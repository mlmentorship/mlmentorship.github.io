---
layout: article
title: Structured Probabilistic Models for Deep Learning Ch16
comments: true
categories: data_science
image:
  teaser: jupyter-main-logo.svg
---

- A structured probabilistic model is a way of describing a probability distribution, using a graph to describe which random variables in the probability distribution interact with each other directly. It's useful in reducing the number of parameters needed to represent a distribution down from all possible combination of all variables to only the combination of variables that are directly connected in the graph. 

- Here we use “graph” in the graph theory sense—a set of vertices connected to one another by a set of edges. Note that a graph only conveys information about dependence of variables not how they are dependent, thus it's very general. The exact relationship between connected variables in a graph is defined through the shape of the conditional distribution. A probabilistic graph defines a probability distribution through the product of a set of local conditional probability distributions. Therefore, one of the major difficulties in graphical modeling is understanding which variables need to be able to interact directly, i.e., which graph structures are most suitable for a given problem. 

- Directed graphical model, are also known as the belief network or Bayesian network. Vertices are random variables in the model, and the direction of the arrow indicates direction of dependence. Some restrictions on the graph structure, such as requiring it to be a tree, can guarantee that operations like computing marginal or conditional distributions over subsets of variables are efficient. 

- Another popular language is that of undirected models, otherwise known as Markov random fields (MRFs) or Markov networks. Unlike directed models there is little structure to the nodes and an undirected graph is usually represented in term of cliques. Cliques are subsets of nodes that are all connected to each other by an edge. For each clique in the graph, a factor $\phi$ (clique potential) measures the affinity of the variables in that clique.  These factors are non-negative and their product defines an unnormalized probability distribution on the Markov network. 

- One key difference between directed modeling and undirected modeling is that directed models are defined directly in terms of probability distributions from the start, while undirected models are defined more loosely by $\phi$ functions that are then converted into probability distributions through normalization. A probability distribution that is obtained by normalized product of factors is called Gibbs distribution. 

- To obtain a valid probability distribution for an undirected graph, we need to divide it by a normalizing  (partition) function. Normalizing function is an integral over all possible combinations of random variables, therefore, the clique factors need to be conducive to efficient calculation of the integral (i.e. integral should exist and domain of variables should be appropriate). Otherwise, the partition function is intractable, in which case we will need to use approximations (e.g. variational inference).

- One key idea to keep in mind while working with undirected models is that the domain of each of the variables has dramatic effect on the kind of probability distribution that a given set of $\phi$ functions corresponds to. Often, it is possible to leverage the effect of a carefully chosen domain of a variable in order to obtain complicated behavior from a relatively simple set of $\phi$ functions. For example, a binary variable RBM!

- Many interesting theoretical results about undirected models depend on the assumption that the unnormalized probability distribution is non-negative. A convenient way to enforce this condition is to use an energy-based model (EBM) where unnormalized probability distribution is the exponential of an energy function $p(x)=exp(-E(x))$. Any such distribution defined by an exponential is an example of a Boltzmann distribution, that's why many energy-based models are called Boltzmann machines. The exponentiation makes each term in the energy function correspond to a factor for a clique because $ exp(a) exp( b) = exp(a + b)$. Each term of the energy function can be thought of as an “expert” that governs a subset of random variables and the experts together enforce a complicated high-dimensional constraint. Many algorithms that operate on probabilistic models only need log of unnormalized probability distribution. Negative of this log probability is called free energy.

## Seperation
- separation and d-separation of a graph is the connectedness of the nodes in the graph. They tell us about conditional independences between nodes that we see in tha graph. There might be additional conditional independencies that we don't know about and thus have not dipicted in the graph. Graphs cannot represent Context-specific independences that dependent on the value of some variables in the network. Similar concepts apply to directed models, except that it is referred to as d-separation. The “d” stands for “dependence.” D-separation for directed graphs is defined the same as separation for undirected graphs. In directed nets, determining whether a path is active is somewhat more complicated.

- In an undirected graph, conditional independence is simply implied by the graph separation. If no path exists between two nodes, or all paths contain an observed variable (passive path), then they are separated (independent). When we draw a graph, we can indicate observed variables by shading them. 

- In a directed graph, due to direction of arrows three cases are possible for two variables("chain", "tree-root", "V").  In the "chain" and "tree-root" structures if the middle node is observed (or conditioned on) the two variables become independent. The "V" structure where middle node is a common child is an exception. This is called the explaining away effect where observing or conditioning on the connecting child will not make the two variables independent. It happens even if any descendant of the child is observed. The only way to block a path of two variables through a "V" structure is to observe none of the descendants of the shared child.

- No probabilistic model is inherently directed or undirected. Instead, some models are most easily described using a directed graph, and some using undirected graph. We should choose the one that better express a specific problem in terms of less dependences. Sometimes a different language becomes more appropriate if we observe a certain subset of variables, or if we wish to perform a different computational task. For example, the directed model description often provides a straightforward approach to efficiently draw samples from while the undirected model formulation is often useful for deriving approximate inference procedures. We can convert between the two languages.

- Directed models can encode explaining away effect (aka immorality; since parents have a child out of wedlock!) that undirected cannot. To convert to an undirected graph, in addition to direct connections, we connect the nodes that are not themselves connected but are mutual parents of a child.

- Undirected graphs can encode a loop (seq of nodes) of length greater than three with no chord (edge connecting two non-consecutive vars of a loop), that directed graph cannot. To convert the undirected model to a directed model, we must triangulate the graph, by ensuring that all loops of greater than length three have a chord (we choose how; discards some independence information). To finish the conversion process, we must assign a direction to each edge. When doing so, we must not create any directed cycles. One way to avoid directed cycles is to impose an ordering over the nodes, and always point each edge from the node that comes earlier in the ordering to the node that comes later in the ordering.

- Factor graphs resolve ambiguity in undirected models regarding factors of unnormalized probability distribution. Random variables are drawn as circles while factors are drawn as squares. No factor may be connected to another factor, nor can a variable be connected to a variable. A variable and a factor are connected if and only if the variable is an argument to the factor.

- Sampling in directed models is easy. We sort the nodes based on the hierarchy of parent child structure and then just sample each variable based on the ordering to produce the whole probability distribution. However, if we observe some part of the graph and want to sample from another part which doesn't come after the observed in the ordering, we need to perform inference!

- Sampling from an undirected model without first converting it to a directed model seems to require resolving cyclical dependencies. Every variable interacts with every other variable, so there is no clear beginning point for the sampling process. We can sample from undirected models by converting them to directed models, but this often requires solving intractable inference problems (to determine the marginal distribution over the root nodes of the new directed graph) or requires introducing so many edges that the resulting directed model becomes intractable. 

- Drawing samples from an undirected graphical model is an expensive, multi-pass process. The conceptually simplest approach is Gibbs sampling. Suppose we have a graphical model over an n-dimensional vector of random variables x. We iteratively visit each variable and draw a sample conditioned on all of the other variables. Due to the separation properties of the graphical model, we can equivalently condition on only the neighbors of a variable. After we have made one pass through the graphical model and sampled all variables, we still do not have a fair sample from p(x). Instead, we must repeat the process and resample all n variables using the updated values of their neighbors. Asymptotically, after many repetitions, this process converges to sampling from the correct distribution. It can be difficult to determine when the samples have reached a sufficiently accurate approximation of the desired distribution.

- In the context of deep learning, the approach most commonly used to model these dependencies is to introduce several latent or “hidden” variables, h. The model can then capture dependencies between any pair of visible variables indirectly. A good model of visible variables (i.e. data) which doesn't contain any latent variables (i.e. autoregressive models) would need to have very large numbers of parents per node in directed or cliques in undirected. An entire field of machine learning called structure learning is devoted to finding visible variables that are tightly coupled to connect and omit edges between others. Most structure learning techniques are a form of greedy search. A structure is proposed, a model with that structure is trained, then given a score. The score rewards high training set accuracy and penalizes model complexity. Candidate structures with a small number of edges added or removed are then proposed as the next step of the search. The search proceeds to a new structure that is expected to increase the score. 

- Using latent variables instead of adaptive structure avoids the need to perform discrete searches and multiple rounds of training. We can learn a model with a fixed structure that imputes the right structure on the visible nodes (representation learning). In a latent variable model, we want to know the hidden variables conditioned the observed variables. This is an inference problem, which we can solve using maximum likelihood principle. Unfortunately, for most interesting deep models, these inference problems are intractable, even when we use a structured graphical model to simplify them. This motivates the use of approximate inference. In the context of deep learning, this usually refers to variational inference, in which we approximate the true distribution p(h | v) by seeking an approximate distribution q(h|v) that is as close to the true one as possible.

- In context of deep learning, we use the same tools of graphical models but differently. We define depth as graphical model depth not computational graph depth. For example, many generative models used for deep learning have no latent variables or only one layer of latent variables, but use deep computational graphs to define the conditional distributions within a model. 

- Traditional models mostly use higher-order terms and structure learning to capture complicated nonlinear interactions between variables. If there are latent variables, they are usually few in number while deep learning models typically have more latent variables than observed variables. Complicated nonlinear interactions between variables are accomplished via indirect connections that flow through multiple latent variables. In deep learning, the latent variables are usually not very easy for a human to interpret, while in graphical models, they are often designed with some specific semantics in mind. 

- Deep graphical models typically have large groups of units that are all connected to other groups of units, so that the interactions between two groups may be described by a single matrix. Traditional graphical models have very few connections and the choice of connections for each variable may be individually designed.

- Traditional approaches to graphical models typically aim to maintain the tractability of exact inference or use a popular approximate inference algorithm is an algorithm called loopy belief propagation. They work well with very sparsely connected graphs. By comparison, models used in deep learning tend to connect each visible unit to very many hidden units, so that hidden can provide a distributed representation. distributed representations usually yiel graphs that are not sparse enough for exact inference and loopy belief propagation and as a consequence, loopy belief propagation is almost never used for deep learning. Most deep models are instead designed to make Gibbs sampling or variational inference algorithms efficient. Deep models have many variables so they group the units into layers with a matrix describing the interaction between two layers. algorithm to be implemented with efficient matrix product operations, or sparsely connected generalizations, like block diagonal matrix products or convolutions.

- Finally, Rather than simplifying the model until all quantities we might want can be computed exactly as in traditional graphical models, in deep learning we increase the power of the model until it is just barely possible to train or use. We often use models whose marginal distributions cannot be computed, and are satisfied simply to draw approximate samples from these models. We often train models with an intractable objective function that we cannot even approximate, but we can obtain an estimate of the gradient. 

- RBMs are quintessential example of how graphical models are used for deep learning. Its units are organized into large groups called layers, visible and hidden, the connectivity between layers is described by a matrix, the connectivity is relatively dense, the model is designed to allow efficient Gibbs sampling, and the emphasis of the model design is on freeing the training algorithm to learn latent variables whose semantics were not specified by the designer. There are no direct interactions between any two visible units or between any two hidden units. RBM is an energy based model energy with a linear energy function of the parameters consisting of three terms corresponding to three matrix multiplication of visible, hidden and interaction. Efficient Gibbs sampling and efficient derivatives make training convenient. 